{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import insightface\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils.video import FileVideoStream\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx \n",
    "def gpu_device(gpu_number=0):\n",
    "    try:\n",
    "        _ = mx.nd.array([1, 2, 3], ctx=mx.gpu(gpu_number))\n",
    "    except mx.MXNetError:\n",
    "        return None\n",
    "    return mx.gpu(gpu_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTX = -1\n",
    "if gpu_device():\n",
    "    CTX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = insightface.app.FaceAnalysis()\n",
    "model.prepare(ctx_id=CTX)\n",
    "\n",
    "embeddings = np.load('assets/embeddings.npz')\n",
    "KNOWN_EMBEDDINGS, KNOWN_SUBJECTS = embeddings['KNOWN_EMBEDDINGS'], embeddings['KNOWN_SUBJECTS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_face(image, face_bbox):\n",
    "    # face patially out of frame\n",
    "    face_bbox[0] = max(face_bbox[0], 0)\n",
    "    face_bbox[1] = max(face_bbox[1], 0)\n",
    "    face_bbox[2] = min(face_bbox[2], image.shape[1])\n",
    "    face_bbox[3] = min(face_bbox[3], image.shape[0])\n",
    "\n",
    "    img_face = image[face_bbox[1]:face_bbox[3],\n",
    "                     face_bbox[0]:face_bbox[2]]\n",
    "    \n",
    "    image[face_bbox[1]:face_bbox[3], face_bbox[0]:face_bbox[2]\n",
    "          ] = cv2.GaussianBlur(img_face, (101, 101), 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_low_quality_trackers(frame, quality_threshold=5):\n",
    "    fid_delete_list = []\n",
    "    for fid in face_trackers.keys():\n",
    "        tracking_quality = face_trackers[fid].update(frame)\n",
    "\n",
    "        if tracking_quality < quality_threshold:\n",
    "            fid_delete_list.append(fid)\n",
    "\n",
    "    for fid in fid_delete_list:\n",
    "        # print(\"Removing fid \" + str(fid) + \" from list of trackers\")\n",
    "        face_trackers.pop(fid, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_face_trackers(frame, faces):\n",
    "    matched_or_created = []\n",
    "    new_faces = []\n",
    "    tracker_mapping = []\n",
    "\n",
    "    for face in faces:\n",
    "        box = face.bbox.astype(np.int)\n",
    "        x, y, w, h = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
    "\n",
    "        # calculate the centerpoint\n",
    "        x_bar = x + 0.5 * w\n",
    "        y_bar = y + 0.5 * h\n",
    "\n",
    "        matched_fid = None\n",
    "        for fid in face_trackers.keys():\n",
    "            tracked_position = face_trackers[fid].get_position()\n",
    "\n",
    "            t_x = int(tracked_position.left())\n",
    "            t_y = int(tracked_position.top())\n",
    "            t_w = int(tracked_position.width())\n",
    "            t_h = int(tracked_position.height())\n",
    "\n",
    "            t_x_bar = t_x + 0.5 * t_w\n",
    "            t_y_bar = t_y + 0.5 * t_h\n",
    "\n",
    "            if ((t_x <= x_bar <= (t_x + t_w)) and (t_y <= y_bar <= (t_y + t_h)) and (x <= t_x_bar <= (x + w)) and (y <= t_y_bar <= (y + h))):\n",
    "                matched_fid = fid\n",
    "\n",
    "        tracker = dlib.correlation_tracker()\n",
    "        tracker.start_track(\n",
    "            frame, dlib.rectangle(x-2, y-1, x+w+1, y+h+1))\n",
    "\n",
    "        global current_fid\n",
    "        if matched_fid is None:\n",
    "            # print(\"New tracker \" + str(current_fid))\n",
    "            face_trackers[current_fid] = tracker\n",
    "            matched_or_created.append(current_fid)\n",
    "\n",
    "            tracker_mapping.append(current_fid)\n",
    "            current_fid += 1\n",
    "        else:\n",
    "            face_trackers[matched_fid] = tracker\n",
    "            matched_or_created.append(matched_fid)\n",
    "            tracker_mapping.append(matched_fid)\n",
    "\n",
    "    delete_fid = []\n",
    "    for fid in face_trackers.keys():\n",
    "        if fid not in matched_or_created:\n",
    "            delete_fid.append(fid)\n",
    "\n",
    "    for fid in delete_fid:\n",
    "        face_trackers.pop(fid, None)\n",
    "\n",
    "    return tracker_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_frame_with_face_recognition(frame, predicted_names, access_list, threshold=1.0):\n",
    "    for fid in face_trackers.keys():\n",
    "        tracked_position = face_trackers[fid].get_position()\n",
    "\n",
    "        t_x = int(tracked_position.left())\n",
    "        t_y = int(tracked_position.top())\n",
    "        t_w = int(tracked_position.width())\n",
    "        t_h = int(tracked_position.height())\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        if fid in predicted_names.keys():\n",
    "            name, conf = predicted_names[fid]\n",
    "            if conf < threshold:\n",
    "                text = f'{name}'\n",
    "#                 cv2.rectangle(frame, (t_x, t_y),(t_x + t_w, t_y + t_h), (80, 236, 18), 2)\n",
    "            else:\n",
    "                text = 'unknown'\n",
    "#                 cv2.rectangle(frame, (t_x, t_y),(t_x + t_w, t_y + t_h), (80, 18, 236), 2)\n",
    "            if text not in access_list:\n",
    "                anonymize_face(frame, face_bbox=[t_x, t_y,\n",
    "                                                 t_x + t_w, t_y + t_h])\n",
    "            else:\n",
    "                cv2.rectangle(frame, (t_x, t_y),(t_x + t_w, t_y + t_h), (80, 236, 18), 2)\n",
    "#             cv2.putText(frame, text, (int(t_x)-1, int(t_y)-5),\n",
    "#                         font, 0.5, (255, 255, 255), 2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = os.path.join('MVI_8215.MOV')\n",
    "recognition_threshold=1.0\n",
    "access_list = ['Rayed', 'Tanjid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frame_to_track = 8\n",
    "predicted_names = {}\n",
    "face_trackers = {}\n",
    "current_fid = 0\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "fvs = FileVideoStream(video_path)\n",
    "fvs.start()\n",
    "time.sleep(0.5)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "videowriter = cv2.VideoWriter('demo.mp4',fourcc, 25, (720, 480))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while fvs.running():\n",
    "    frame = fvs.read()\n",
    "    if frame is None:\n",
    "        fvs.stop()\n",
    "        break\n",
    "    else:\n",
    "        frame = cv2.resize(frame, (720, 480))\n",
    "\n",
    "        delete_low_quality_trackers(frame)\n",
    "\n",
    "        if frame_count % num_frame_to_track == 0:\n",
    "            faces = model.get(frame)\n",
    "\n",
    "            tracker_mapping = update_face_trackers(\n",
    "                frame, faces)\n",
    "\n",
    "            face_embs = []\n",
    "            for face_idx, face in enumerate(faces):\n",
    "                face_embs.append(face.normed_embedding)\n",
    "\n",
    "            if len(face_embs) > 0:\n",
    "                face_embs = np.asarray(face_embs)\n",
    "                euclidin_dist = euclidean_distances(\n",
    "                    face_embs, KNOWN_EMBEDDINGS)\n",
    "                predictions = np.argmin(euclidin_dist, axis=1)\n",
    "                pred_dist = euclidin_dist[np.arange(\n",
    "                    euclidin_dist.shape[0]), predictions]\n",
    "\n",
    "            for i, f_id in enumerate(tracker_mapping):\n",
    "                if f_id in predicted_names:\n",
    "                    old_n, old_dist = predicted_names[f_id]\n",
    "                    if pred_dist[i] < old_dist:\n",
    "                        predicted_names[f_id] = (\n",
    "                            KNOWN_SUBJECTS[predictions[i]], pred_dist[i])\n",
    "                else:\n",
    "                    predicted_names[f_id] = (\n",
    "                        KNOWN_SUBJECTS[predictions[i]], pred_dist[i])\n",
    "\n",
    "        rec_frame = annotate_frame_with_face_recognition(\n",
    "            frame, predicted_names, access_list, threshold=recognition_threshold)\n",
    "        \n",
    "        frame_count += 1\n",
    "        if frame_count % min(10, frame_count) == 0:\n",
    "            end_time = time.time()\n",
    "            fps = 10/(end_time-start_time)\n",
    "            start_time = time.time()\n",
    "        fps_text = f'Processing {fps:0.2f} frames per second'\n",
    "\n",
    "        cv2.putText(rec_frame, fps_text, (20, 40),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        videowriter.write(frame)\n",
    "\n",
    "\n",
    "videowriter.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (MXNet 1.8 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/mxnet-1.8-gpu-py37-cu110-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
